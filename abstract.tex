\begin{abstract}
Automatic text classification is an active field of research over the last decades due to the rapid growth of online documents. As a consequence, several scientific publications provide an overview of current classification techniques. The general trend of these publications is that several Machine Learning techniques make progress in text classification problems. Common research areas within text classification are topics, emails, and sentiment classification. \\ 
\\
The general approach in these tasks is similar in extracting the meaning of the text (features) to find the appropriate class or label. However, the results of these techniques depend on to which extent a technique is able to model the underlying structure of the documents that belong to labels. In this process, a variety of techniques, combined with a mixture of parameters are chosen in order to model a classifier. Finding suitable structures, architectures, and techniques for text classification is, in particular, a challenge for researchers.\\
\\
Therefore, in this thesis, i will be focussing on applying state-of-the-art technics Google BERT, which is using a pre-trained model to tackle NLP problematics and can be used in many different languages (103 actually). As shown by \citeauthor{Devlin2018}. , BERT can be easily fine-tuned to be part of every project. Nonetheless, it as not been shown that BERT could handle short text and/or word for classification. 
\end{abstract}
